{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ei4AcgfpV1kd"
   },
   "source": [
    "# NN Ensemble implementation of Zimmerman, Steven and Fox, Chris and Kruschwitz, Udo Improving Hate Speech Detection with Deep Learning Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sNw6YZi6qK3g"
   },
   "source": [
    "## Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QTEqXzVV1ke"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras import initializers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(21)\n",
    "\n",
    "# Note tqdm import try\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except:\n",
    "    import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NeUyr7qaV1ki"
   },
   "source": [
    "## Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1588522763765,
     "user": {
      "displayName": "Samridha Man Shrestha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWM1giZm-4hM3_aud8FxlOUc8VWuoYWktFbs7VDA=s64",
      "userId": "14722659845832153120"
     },
     "user_tz": -240
    },
    "id": "lhk18szsV1ki",
    "outputId": "56a6e058-513a-4f67-f478-0031025eb8e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  ...  class                                              tweet\n",
       "0           0      3  ...      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1           1      3  ...      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2           2      3  ...      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3           3      3  ...      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4           4      6  ...      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_davidson = pd.read_csv(\"hate_speech_labelled_data/labeled_data.csv\")\n",
    "X_train_davidson.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXu00UY5V1ku"
   },
   "source": [
    "### Columns key:\n",
    "\n",
    "-   count = number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were determined to be unreliable by CF).\n",
    "\n",
    "\n",
    "-   hate_speech = number of CF users who judged the tweet to be hate speech.\n",
    "\n",
    "\n",
    "-   offensive_language = number of CF users who judged the tweet to be offensive.\n",
    "\n",
    "\n",
    "-   neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "\n",
    "\n",
    "-   class = class label for majority of CF users.\n",
    "\n",
    "    -   0 - hate speech\n",
    "    -   1 - offensive  language\n",
    "    -   2 - neither\n",
    "\n",
    "-   tweet = raw tweet text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1249,
     "status": "ok",
     "timestamp": 1588522767745,
     "user": {
      "displayName": "Samridha Man Shrestha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWM1giZm-4hM3_aud8FxlOUc8VWuoYWktFbs7VDA=s64",
      "userId": "14722659845832153120"
     },
     "user_tz": -240
    },
    "id": "hV-qiF1GV1kv",
    "outputId": "7c6ead28-656c-4444-a160-e1184cb58d8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb3bfcb5eb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD7CAYAAACIYvgKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAWiklEQVR4nO3df7BfdZ3f8eerQVjXH0uQu2k2ISbYuDvg7Ea4g9RVyy4rBOwabDs2zFaiS41U6Oh0p924zhRHyxS769phanFQM4YZC7KiktZQjBHXaW2QoDEQFHOJUJKJSZa4onWHXfDdP76fq4fLvbnfe7/3fhPJ8zFz5nu+7/M553y+536T1z3nc77fm6pCknRi+3vHugOSpGPPMJAkGQaSJMNAkoRhIEnCMJAk0UcYJDkjyd1JHkyyO8m7Wv20JFuT7GmPC1s9SW5IMpZkV5JzOtta19rvSbKuUz83yf1tnRuSZD5erCRpcv2cGTwF/FFVnQWcD1yd5CxgA7CtqlYC29pzgEuAlW1aD9wIvfAArgVeBZwHXDseIK3N2zvrrR78pUmS+nXSdA2q6gBwoM3/KMm3gSXAGuCC1mwT8BXgj1v95up9mm17klOTLG5tt1bVEYAkW4HVSb4CvLiqtrf6zcBlwJ1H69fpp59ey5cvn8FLlSTdd999f1VVIxPr04ZBV5LlwCuBe4BFLSgAvg8savNLgMc6q+1rtaPV901SP6rly5ezY8eOmXRfkk54SR6drN73AHKSFwK3A++uqie6y9pZwLx/r0WS9Ul2JNlx+PDh+d6dJJ0w+gqDJM+jFwSfqqrPtvLBdvmH9nio1fcDZ3RWX9pqR6svnaT+LFV1U1WNVtXoyMizznIkSbPUz91EAT4BfLuq/ryzaDMwfkfQOuCOTv2KdlfR+cAP2+Wku4CLkixsA8cXAXe1ZU8kOb/t64rOtiRJQ9DPmMFvA28B7k+ys9X+BLgeuC3JlcCjwJvbsi3ApcAY8BPgbQBVdSTJB4B7W7v3jw8mA+8EPgk8n97A8VEHjyVJcyu/qF9hPTo6Wg4gS9LMJLmvqkYn1v0EsiTJMJAkGQaSJAwDSRIz/ASypOkt3/CFY7bvR65/wzHbt36xeWYgSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEmijzBIsjHJoSQPdGqfTrKzTY+M/23kJMuT/E1n2Uc765yb5P4kY0luSJJWPy3J1iR72uPC+XihkqSp9XNm8ElgdbdQVf+8qlZV1SrgduCzncUPjy+rqqs69RuBtwMr2zS+zQ3AtqpaCWxrzyVJQzRtGFTVV4Ejky1rv92/GbjlaNtIshh4cVVtr6oCbgYua4vXAJva/KZOXZI0JIOOGbwWOFhVezq1FUm+meQvk7y21ZYA+zpt9rUawKKqOtDmvw8sGrBPkqQZGvQvnV3OM88KDgDLqurxJOcCn09ydr8bq6pKUlMtT7IeWA+wbNmyWXZZkjTRrM8MkpwE/BPg0+O1qnqyqh5v8/cBDwMvB/YDSzurL201gIPtMtL45aRDU+2zqm6qqtGqGh0ZGZlt1yVJEwxymej3gO9U1c8u/yQZSbKgzZ9Jb6B4b7sM9ESS89s4wxXAHW21zcC6Nr+uU5ckDUk/t5beAvwf4NeT7EtyZVu0lmcPHL8O2NVuNf0McFVVjQ8+vxP4ODBG74zhzla/Hnh9kj30Aub6AV6PJGkWph0zqKrLp6i/dZLa7fRuNZ2s/Q7gFZPUHwcunK4fkqT54yeQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSaK/v4G8McmhJA90au9Lsj/JzjZd2ln2niRjSR5KcnGnvrrVxpJs6NRXJLmn1T+d5OS5fIGSpOn1c2bwSWD1JPUPV9WqNm0BSHIWsBY4u63zX5MsSLIA+AhwCXAWcHlrC/DBtq1/APwAuHKQFyRJmrlpw6Cqvgoc6XN7a4Bbq+rJqvoeMAac16axqtpbVX8L3AqsSRLgd4HPtPU3AZfN8DVIkgY0yJjBNUl2tctIC1ttCfBYp82+Vpuq/hLgr6vqqQl1SdIQzTYMbgReBqwCDgAfmrMeHUWS9Ul2JNlx+PDhYexSkk4IswqDqjpYVU9X1U+Bj9G7DASwHzij03Rpq01Vfxw4NclJE+pT7femqhqtqtGRkZHZdF2SNIlZhUGSxZ2nbwLG7zTaDKxNckqSFcBK4OvAvcDKdufQyfQGmTdXVQF3A/+srb8OuGM2fZIkzd5J0zVIcgtwAXB6kn3AtcAFSVYBBTwCvAOgqnYnuQ14EHgKuLqqnm7buQa4C1gAbKyq3W0XfwzcmuQ/AN8EPjFnr06S1Jdpw6CqLp+kPOV/2FV1HXDdJPUtwJZJ6nv5+WUmSdIx4CeQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgSaKPMEiyMcmhJA90an+a5DtJdiX5XJJTW315kr9JsrNNH+2sc26S+5OMJbkhSVr9tCRbk+xpjwvn44VKkqbWz5nBJ4HVE2pbgVdU1W8C3wXe01n2cFWtatNVnfqNwNuBlW0a3+YGYFtVrQS2teeSpCGaNgyq6qvAkQm1L1bVU+3pdmDp0baRZDHw4qraXlUF3Axc1havATa1+U2duiRpSOZizOAPgTs7z1ck+WaSv0zy2lZbAuzrtNnXagCLqupAm/8+sGgO+iRJmoGTBlk5yXuBp4BPtdIBYFlVPZ7kXODzSc7ud3tVVUnqKPtbD6wHWLZs2ew7Lkl6hlmfGSR5K/CPgT9ol36oqier6vE2fx/wMPByYD/PvJS0tNUADrbLSOOXkw5Ntc+quqmqRqtqdGRkZLZdlyRNMKswSLIa+HfAG6vqJ536SJIFbf5MegPFe9tloCeSnN/uIroCuKOtthlY1+bXdeqSpCGZ9jJRkluAC4DTk+wDrqV399ApwNZ2h+j2dufQ64D3J/k74KfAVVU1Pvj8Tnp3Jj2f3hjD+DjD9cBtSa4EHgXePCevTJLUt2nDoKoun6T8iSna3g7cPsWyHcArJqk/Dlw4XT8kSfPHTyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSRJ9hkGRjkkNJHujUTkuyNcme9riw1ZPkhiRjSXYlOaezzrrWfk+SdZ36uUnub+vckPaHlSVJw9HvmcEngdUTahuAbVW1EtjWngNcAqxs03rgRuiFB3At8CrgPODa8QBpbd7eWW/iviRJ86ivMKiqrwJHJpTXAJva/Cbgsk795urZDpyaZDFwMbC1qo5U1Q+ArcDqtuzFVbW9qgq4ubMtSdIQDDJmsKiqDrT57wOL2vwS4LFOu32tdrT6vknqkqQhmZMB5PYbfc3Fto4myfokO5LsOHz48HzvTpJOGIOEwcF2iYf2eKjV9wNndNotbbWj1ZdOUn+WqrqpqkaranRkZGSArkuSugYJg83A+B1B64A7OvUr2l1F5wM/bJeT7gIuSrKwDRxfBNzVlj2R5Px2F9EVnW1JkobgpH4aJbkFuAA4Pck+encFXQ/cluRK4FHgza35FuBSYAz4CfA2gKo6kuQDwL2t3furanxQ+p307lh6PnBnmyRJQ9JXGFTV5VMsunCStgVcPcV2NgIbJ6nvAF7RT18kSXPPTyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSxABhkOTXk+zsTE8keXeS9yXZ36lf2lnnPUnGkjyU5OJOfXWrjSXZMOiLkiTNTF9/A3kyVfUQsAogyQJgP/A54G3Ah6vqz7rtk5wFrAXOBn4N+FKSl7fFHwFeD+wD7k2yuaoenG3fJEkzM+swmOBC4OGqejTJVG3WALdW1ZPA95KMAee1ZWNVtRcgya2trWEgSUMyV2MGa4FbOs+vSbIrycYkC1ttCfBYp82+VpuqLkkakoHDIMnJwBuBv2ilG4GX0buEdAD40KD76OxrfZIdSXYcPnx4rjYrSSe8uTgzuAT4RlUdBKiqg1X1dFX9FPgYP78UtB84o7Pe0labqv4sVXVTVY1W1ejIyMgcdF2SBHMTBpfTuUSUZHFn2ZuAB9r8ZmBtklOSrABWAl8H7gVWJlnRzjLWtraSpCEZaAA5yQvo3QX0jk75PyVZBRTwyPiyqtqd5DZ6A8NPAVdX1dNtO9cAdwELgI1VtXuQfkmSZmagMKiq/we8ZELtLUdpfx1w3ST1LcCWQfoiSZo9P4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEnMQBkkeSXJ/kp1JdrTaaUm2JtnTHhe2epLckGQsya4k53S2s66135Nk3aD9kiT1b67ODH6nqlZV1Wh7vgHYVlUrgW3tOcAlwMo2rQduhF54ANcCrwLOA64dDxBJ0vybr8tEa4BNbX4TcFmnfnP1bAdOTbIYuBjYWlVHquoHwFZg9Tz1TZI0wVyEQQFfTHJfkvWttqiqDrT57wOL2vwS4LHOuvtabaq6JGkITpqDbbymqvYn+VVga5LvdBdWVSWpOdgPLWzWAyxbtmwuNilJYg7ODKpqf3s8BHyO3jX/g+3yD+3xUGu+Hzijs/rSVpuqPnFfN1XVaFWNjoyMDNp1SVIzUBgkeUGSF43PAxcBDwCbgfE7gtYBd7T5zcAV7a6i84EftstJdwEXJVnYBo4vajVJ0hAMeploEfC5JOPb+m9V9T+T3AvcluRK4FHgza39FuBSYAz4CfA2gKo6kuQDwL2t3fur6siAfZMk9WmgMKiqvcBvTVJ/HLhwknoBV0+xrY3AxkH6I0maHT+BLEkyDCRJhoEkCcNAksTcfOhMkk44yzd84Zjs95Hr3zAv2/XMQJJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSxABhkOSMJHcneTDJ7iTvavX3JdmfZGebLu2s854kY0keSnJxp7661caSbBjsJUmSZmqQr7B+CvijqvpGkhcB9yXZ2pZ9uKr+rNs4yVnAWuBs4NeALyV5eVv8EeD1wD7g3iSbq+rBAfomSZqBWYdBVR0ADrT5HyX5NrDkKKusAW6tqieB7yUZA85ry8aqai9AkltbW8NAkoZkTsYMkiwHXgnc00rXJNmVZGOSha22BHiss9q+VpuqLkkakoHDIMkLgduBd1fVE8CNwMuAVfTOHD406D46+1qfZEeSHYcPH56rzUrSCW+gMEjyPHpB8Kmq+ixAVR2sqqer6qfAx/j5paD9wBmd1Ze22lT1Z6mqm6pqtKpGR0ZGBum6JKljkLuJAnwC+HZV/XmnvrjT7E3AA21+M7A2ySlJVgArga8D9wIrk6xIcjK9QebNs+2XJGnmBrmb6LeBtwD3J9nZan8CXJ5kFVDAI8A7AKpqd5Lb6A0MPwVcXVVPAyS5BrgLWABsrKrdA/RLkjRDg9xN9L+ATLJoy1HWuQ64bpL6lqOtJ0maX34CWZJkGEiSDANJEoaBJAnDQJKEYSBJYrDPGfzCWr7hC8dkv49c/4Zjsl9Jmo5nBpIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJI4jsIgyeokDyUZS7LhWPdHkk4kx0UYJFkAfAS4BDgLuDzJWce2V5J04jguwgA4Dxirqr1V9bfArcCaY9wnSTphHC9hsAR4rPN8X6tJkobgF+rvGSRZD6xvT3+c5KFZbup04K/mplf9ywenbXJM+tUH+zUzx6xf07zHPF4zc1z2Kx8cuF8vnax4vITBfuCMzvOlrfYMVXUTcNOgO0uyo6pGB93OXLNfM2O/ZsZ+zcyJ1q/j5TLRvcDKJCuSnAysBTYf4z5J0gnjuDgzqKqnklwD3AUsADZW1e5j3C1JOmEcF2EAUFVbgC1D2t3Al5rmif2aGfs1M/ZrZk6ofqWq5mO7kqRfIMfLmIEk6Rh6zoXBdF9rkeSUJJ9uy+9Jsryz7D2t/lCSi4fcr3+T5MEku5JsS/LSzrKnk+xs05wOrPfRr7cmOdzZ/7/sLFuXZE+b1g25Xx/u9Om7Sf66s2xejleSjUkOJXlgiuVJckPr864k53SWzeexmq5ff9D6c3+SryX5rc6yR1p9Z5IdQ+7XBUl+2PlZ/fvOsnn7epo++vVvO316oL2fTmvL5vN4nZHk7vb/wO4k75qkzfy9x6rqOTPRG3x+GDgTOBn4FnDWhDbvBD7a5tcCn27zZ7X2pwAr2nYWDLFfvwP8cpv/V+P9as9/fAyP11uB/zLJuqcBe9vjwja/cFj9mtD+X9O76WC+j9frgHOAB6ZYfilwJxDgfOCe+T5Wffbr1eP7o/eVL/d0lj0CnH6MjtcFwP8Y9Oc/1/2a0Pb3gS8P6XgtBs5p8y8CvjvJv8d5e489184M+vlaizXApjb/GeDCJGn1W6vqyar6HjDWtjeUflXV3VX1k/Z0O73PWsy3Qb4G5GJga1UdqaofAFuB1ceoX5cDt8zRvqdUVV8FjhylyRrg5urZDpyaZDHze6ym7VdVfa3tF4b33urneE1lXr+eZob9Gsp7C6CqDlTVN9r8j4Bv8+xvYpi399hzLQz6+VqLn7WpqqeAHwIv6XPd+exX15X00n/cLyXZkWR7ksvmqE8z6dc/baekn0ky/uHA4+J4tctpK4Avd8rzdbymM1W/j6evW5n43irgi0nuS+8T/sP2D5N8K8mdSc5utePieCX5ZXr/od7eKQ/leKV3+fqVwD0TFs3be+y4ubVUPUn+BTAK/KNO+aVVtT/JmcCXk9xfVQ8PqUv/Hbilqp5M8g56Z1W/O6R992Mt8JmqerpTO5bH67iV5HfohcFrOuXXtGP1q8DWJN9pvzkPwzfo/ax+nORS4PPAyiHtux+/D/zvquqeRcz78UryQnoB9O6qemIut300z7Uzg36+1uJnbZKcBPwK8Hif685nv0jye8B7gTdW1ZPj9ara3x73Al+h9xvDUPpVVY93+vJx4Nx+153PfnWsZcJp/Dwer+lM1e/5PFZ9SfKb9H5+a6rq8fF651gdAj7H3F0anVZVPVFVP27zW4DnJTmd4+B4NUd7b83L8UryPHpB8Kmq+uwkTebvPTYfAyHHaqJ3prOX3mWD8YGnsye0uZpnDiDf1ubP5pkDyHuZuwHkfvr1SnqDZisn1BcCp7T504E9zNFgWp/9WtyZfxOwvX4+YPW91r+Fbf60YfWrtfsNegN6GcbxattcztQDom/gmYN7X5/vY9Vnv5bRGwN79YT6C4AXdea/BqweYr/+/vjPjt5/qv+3Hbu+fv7z1a+2/FfojSu8YFjHq732m4H/fJQ28/Yem7ODe7xM9Ebbv0vvP9b3ttr76f22DfBLwF+0fxxfB87srPvett5DwCVD7teXgIPAzjZtbvVXA/e3fxD3A1cOuV//Edjd9n838Buddf+wHccx4G3D7Fd7/j7g+gnrzdvxovdb4gHg7+hdk70SuAq4qi0PvT/S9HDb9+iQjtV0/fo48IPOe2tHq5/ZjtO32s/4vUPu1zWd99Z2OmE12c9/WP1qbd5K74aS7nrzfbxeQ29MYlfnZ3XpsN5jfgJZkvScGzOQJM2CYSBJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJKA/w/DqQlXF0MlkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_davidson['class'].hist(grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uc1mK2lTV1ky"
   },
   "source": [
    "This histogram shows the imbalanced nature of the task - most tweets containing \"hate\" words as defined by Hatebase were \n",
    "only considered to be offensive by the CF coders. More tweets were considered to be neither hate speech nor offensive language than were considered hate speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAJcNumi7NOX"
   },
   "source": [
    "# Ensemble Neural Network *Implementation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lyVPlZgE7O58"
   },
   "source": [
    "## Import required and custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EuH56Nv3lM3"
   },
   "outputs": [],
   "source": [
    "import util.nn_ensemble.evaluation as evaluation\n",
    "import util.nn_ensemble.helper as helper\n",
    "import util.nn_ensemble.nlp as nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAmdjdfWk5o5"
   },
   "source": [
    "## Utility function\n",
    "\n",
    "For preprocessing tweets for acquiring the word to vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2AdkRfmk3RY"
   },
   "outputs": [],
   "source": [
    "def get_cnn_embeddings(word_embeddings, tweets_tokenized, max_tokens=50):\n",
    "    '''twitter embedding model only'''\n",
    "    corpus_vecs = []\n",
    "    for tweet in tweets_tokenized:\n",
    "        tweet_vecs = [[0.0 for x in range(400)] for x in range(max_tokens)]\n",
    "        for cnt, token in enumerate(tweet):\n",
    "            try:\n",
    "                tweet_vecs[cnt] = (word_embeddings[token].tolist())\n",
    "            except:\n",
    "                continue\n",
    "        # tweet_vecs.append(embedding_sum/tweet_length)  # NOTE: L1 and High C 10+  better for this scenario\n",
    "        # NOTE: L2 and Low C .01- better for this scenario\n",
    "        corpus_vecs.append(tweet_vecs)\n",
    "    return np.array(corpus_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tpb4oWeHZnGb"
   },
   "source": [
    "## Defining CNN and Ensemble model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KrXCufHLdYRt"
   },
   "outputs": [],
   "source": [
    "class CNN_model:\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size=50,\n",
    "                 output_size=3,\n",
    "                 loss='binary_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'],\n",
    "                 random_seed=87):\n",
    "        self.input_size = input_size     # tokens\n",
    "        self.output_size = output_size\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv1D(filters=150, kernel_size=3,\n",
    "                              padding='same', activation='relu',\n",
    "                              input_shape=(input_size, 400)))\n",
    "        self.model.add(GlobalMaxPooling1D())\n",
    "        self.model.add(Dense(250, activation='relu'))\n",
    "        self.model.add(Dense(3, activation='sigmoid'))\n",
    "        self.model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    def fit(self, X_train, y_train,\n",
    "            batch_size=32,\n",
    "            epochs=3,\n",
    "            validation_split=0.2,\n",
    "            **kwargs):\n",
    "        self.model.fit(X_train,\n",
    "                       y_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=epochs,\n",
    "                       validation_split=validation_split,\n",
    "                       **kwargs)\n",
    "\n",
    "    def predict(self, X, verbose=0):\n",
    "        return self.model.predict(X, verbose=verbose)\n",
    "\n",
    "    def evaluate_model(self, y_test, y_pred):\n",
    "        # output evaluation data\n",
    "        print('--------- INDIVIDUAL CNN Model results ---------')\n",
    "        print('--------- F-1/precision/recall report  ---------')\n",
    "        print('---------         MACRO F1             ---------')\n",
    "        print(f1_score(y_test, y_pred, average='macro'))\n",
    "        print('---------         F1 Matrix            ---------')\n",
    "        print(evaluation.evaluate_results(y_test, y_pred))\n",
    "\n",
    "    def get_model_summary(self):\n",
    "        return self.model.summary()\n",
    "\n",
    "    def save_model(self, save_model_path):\n",
    "        self.model.save(save_model_path)  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "    def load_model(self, load_model_path):\n",
    "        self.model = load_model(load_model_path)\n",
    "\n",
    "\n",
    "class Ensemble_CNN_model:\n",
    "\n",
    "    def __init__(self,\n",
    "                 load_weight_path=None,\n",
    "                 num_ensemble_models=10,\n",
    "                 input_size=50,\n",
    "                 output_size=3,\n",
    "                 random_seed=87):\n",
    "\n",
    "        self.ensemble_cnns = [None]*num_ensemble_models\n",
    "\n",
    "        for i in range(num_ensemble_models):\n",
    "            np.random.seed(int(random_seed*(i+1)))\n",
    "            self.ensemble_cnns[i] = CNN_model(input_size=input_size,\n",
    "                                              output_size=output_size)\n",
    "            if load_weight_path:\n",
    "                try:\n",
    "                    self.ensemble_cnns[i].load_model(load_weight_path+f'_{i}')\n",
    "                except:\n",
    "                    print(\n",
    "                        f'Model weight not available: {load_weight_path}_{i}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        aggregate_y_pred = []\n",
    "        encoder = None\n",
    "\n",
    "        RANGE = len(self.ensemble_cnns)\n",
    "        for cnn_model in self.ensemble_cnns:\n",
    "            y_soft_max = cnn_model.predict(X)\n",
    "            y_pred = y_soft_max.argmax(axis=1)\n",
    "            aggregate_y_pred.append(y_soft_max)\n",
    "\n",
    "        # ADD ALL RESULTS\n",
    "        sum_of_ys = aggregate_y_pred[0]\n",
    "        for i in [x + 1 for x in range(RANGE - 1)]:\n",
    "            sum_of_ys += aggregate_y_pred[i]\n",
    "\n",
    "        # DIVIDE BY RANGE FOR MEAN\n",
    "        sum_of_ys /= RANGE\n",
    "\n",
    "        # ENCODE PREDS\n",
    "        encoded_preds = sum_of_ys.argmax(axis=1)\n",
    "        print(len(sum_of_ys), len(encoded_preds))\n",
    "        return encoded_preds\n",
    "\n",
    "    def fit_and_eval(self, X_train, y_train, X_test, y_test,\n",
    "                     save_weight_path=None,\n",
    "                     validation_split=0.2,\n",
    "                     batch_size=32,\n",
    "                     epochs=3,\n",
    "                     **kwargs):\n",
    "        aggregate_y_pred = []\n",
    "        encoder = None\n",
    "\n",
    "        RANGE = len(self.ensemble_cnns)\n",
    "        for cnn_model in self.ensemble_cnns:\n",
    "            y_encoder, y_one_hot = helper.one_hot_encode_y(y_train)\n",
    "            cnn_model.fit(X_train, y_one_hot, epochs=epochs,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "            if save_weight_path:\n",
    "                cnn_model.save_model(save_weight_path)\n",
    "\n",
    "            y_soft_max = cnn_model.predict(X_test)\n",
    "            encoded_preds = y_soft_max.argmax(axis=1)\n",
    "            decoded_preds = y_encoder.inverse_transform(encoded_preds)\n",
    "\n",
    "            cnn_model.evaluate_model(\n",
    "                y_test, decoded_preds)  # print indv results\n",
    "            aggregate_y_pred.append(y_soft_max)\n",
    "\n",
    "        # ADD ALL RESULTS\n",
    "        sum_of_ys = aggregate_y_pred[0]\n",
    "        for i in [x + 1 for x in range(RANGE - 1)]:\n",
    "            sum_of_ys += aggregate_y_pred[i]\n",
    "\n",
    "        # DIVIDE BY RANGE FOR MEAN\n",
    "        sum_of_ys /= RANGE\n",
    "\n",
    "        # ENCODE PREDS\n",
    "        encoded_preds = sum_of_ys.argmax(axis=1)\n",
    "        decoded_preds = y_encoder.inverse_transform(encoded_preds)\n",
    "        print(len(sum_of_ys), len(encoded_preds), len(decoded_preds))\n",
    "        self.evaluate_model(y_test, decoded_preds)\n",
    "\n",
    "    def evaluate_model(self, y_test, y_pred):\n",
    "        print('--------- FINAL ENSEMBLE Model results ---------')\n",
    "        print('---------  F-1/precision/recall report ---------')\n",
    "        print('---------            MACRO F1:         ---------')\n",
    "        print(f1_score(y_test, y_pred, average='macro'))\n",
    "        print('---------            F1 Matrix         ---------')\n",
    "        print(evaluation.evaluate_results(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjdyTDc6D0Mo"
   },
   "source": [
    "## Load the word vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141111,
     "status": "ok",
     "timestamp": 1588522970364,
     "user": {
      "displayName": "Samridha Man Shrestha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWM1giZm-4hM3_aud8FxlOUc8VWuoYWktFbs7VDA=s64",
      "userId": "14722659845832153120"
     },
     "user_tz": -240
    },
    "id": "YF3IgIOsAnuV",
    "outputId": "983e29c2-bca1-4e6e-f3e9-10279fd1a70d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('pre_trained_models/word2vec_twitter_tokens.bin', \n",
    "                                                 binary=True,\n",
    "                                                 unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 271391,
     "status": "ok",
     "timestamp": 1588523102392,
     "user": {
      "displayName": "Samridha Man Shrestha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWM1giZm-4hM3_aud8FxlOUc8VWuoYWktFbs7VDA=s64",
      "userId": "14722659845832153120"
     },
     "user_tz": -240
    },
    "id": "o_SjBZfY2w8E",
    "outputId": "a7d12697-9d8f-451c-addc-d44a80ff4521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features\n"
     ]
    }
   ],
   "source": [
    "# --------- EMBEDDING MODELS ----------- #\n",
    "#     Load tweet embeddings lookup       #\n",
    "# ---------------- GODIN --------------- #\n",
    "\n",
    "print('Extracting features')\n",
    "X_train = get_cnn_embeddings(word_vectors,\n",
    "                             map(lambda y: nlp.replace_tokens(y),\n",
    "                                 nlp.tokenize_tweets(X_train_davidson['tweet'],\n",
    "                                                     lower_case=LOWER_CASE_TOKENS)),\n",
    "                             max_tokens=50)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = (X_train_davidson['class'].astype(int))\n",
    "\n",
    "# Concatenate wassem data to davidson data\n",
    "X_train = np.concatenate([X_train, X_data_w])\n",
    "Y_train = np.concatenate([Y_train, y_data_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu5GS-BFqWmm"
   },
   "outputs": [],
   "source": [
    "# sklearn train_test_split\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_train, Y_train, test_size=0.15, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNg_b4hbTztl"
   },
   "source": [
    "## Train the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 462855,
     "status": "ok",
     "timestamp": 1588524882482,
     "user": {
      "displayName": "Samridha Man Shrestha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWM1giZm-4hM3_aud8FxlOUc8VWuoYWktFbs7VDA=s64",
      "userId": "14722659845832153120"
     },
     "user_tz": -240
    },
    "id": "pkGD80ihTy5a",
    "outputId": "eb81bd1e-5134-4fad-9212-51c96396094d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 330us/step - loss: 0.1890 - accuracy: 0.9297 - val_loss: 0.1769 - val_accuracy: 0.9410\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 317us/step - loss: 0.1311 - accuracy: 0.9497 - val_loss: 0.1636 - val_accuracy: 0.9422\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.0938 - accuracy: 0.9642 - val_loss: 0.1794 - val_accuracy: 0.9336\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.0572 - accuracy: 0.9786 - val_loss: 0.2299 - val_accuracy: 0.9236\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7403229181477727\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3531    0.5667    0.4351       210\n",
      "           1     0.9526    0.9195    0.9358      2908\n",
      "           2     0.8693    0.8317    0.8501       600\n",
      "\n",
      "    accuracy                         0.8854      3718\n",
      "   macro avg     0.7250    0.7726    0.7403      3718\n",
      "weighted avg     0.9053    0.8854    0.8937      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 327us/step - loss: 0.1909 - accuracy: 0.9282 - val_loss: 0.1600 - val_accuracy: 0.9431\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 317us/step - loss: 0.1324 - accuracy: 0.9505 - val_loss: 0.1558 - val_accuracy: 0.9415\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 320us/step - loss: 0.0971 - accuracy: 0.9640 - val_loss: 0.1732 - val_accuracy: 0.9428\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 321us/step - loss: 0.0613 - accuracy: 0.9768 - val_loss: 0.2023 - val_accuracy: 0.9358\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.6938601896466766\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4845    0.2238    0.3062       210\n",
      "           1     0.9175    0.9632    0.9398      2908\n",
      "           2     0.8592    0.8133    0.8356       600\n",
      "\n",
      "    accuracy                         0.8973      3718\n",
      "   macro avg     0.7537    0.6668    0.6939      3718\n",
      "weighted avg     0.8836    0.8973    0.8872      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 331us/step - loss: 0.1889 - accuracy: 0.9284 - val_loss: 0.1616 - val_accuracy: 0.9403\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 323us/step - loss: 0.1308 - accuracy: 0.9510 - val_loss: 0.1760 - val_accuracy: 0.9324\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 321us/step - loss: 0.0934 - accuracy: 0.9648 - val_loss: 0.1860 - val_accuracy: 0.9351\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.0538 - accuracy: 0.9802 - val_loss: 0.2313 - val_accuracy: 0.9397\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7030539750933938\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4646    0.2190    0.2977       210\n",
      "           1     0.9276    0.9611    0.9441      2908\n",
      "           2     0.8630    0.8717    0.8673       600\n",
      "\n",
      "    accuracy                         0.9048      3718\n",
      "   macro avg     0.7518    0.6840    0.7031      3718\n",
      "weighted avg     0.8911    0.9048    0.8952      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 329us/step - loss: 0.1896 - accuracy: 0.9286 - val_loss: 0.1616 - val_accuracy: 0.9425\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 317us/step - loss: 0.1301 - accuracy: 0.9510 - val_loss: 0.1684 - val_accuracy: 0.9432\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.0933 - accuracy: 0.9647 - val_loss: 0.1909 - val_accuracy: 0.9403\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.0546 - accuracy: 0.9809 - val_loss: 0.2173 - val_accuracy: 0.9373\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7305003473901528\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4487    0.3333    0.3825       210\n",
      "           1     0.9432    0.9419    0.9425      2908\n",
      "           2     0.8283    0.9083    0.8665       600\n",
      "\n",
      "    accuracy                         0.9021      3718\n",
      "   macro avg     0.7401    0.7279    0.7305      3718\n",
      "weighted avg     0.8967    0.9021    0.8986      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 328us/step - loss: 0.1902 - accuracy: 0.9301 - val_loss: 0.1682 - val_accuracy: 0.9361\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 317us/step - loss: 0.1318 - accuracy: 0.9507 - val_loss: 0.1640 - val_accuracy: 0.9424\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 318us/step - loss: 0.0948 - accuracy: 0.9642 - val_loss: 0.1862 - val_accuracy: 0.9433\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 320us/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.2397 - val_accuracy: 0.9380\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7508401570346809\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5127    0.3857    0.4402       210\n",
      "           1     0.9502    0.9384    0.9443      2908\n",
      "           2     0.8125    0.9317    0.8680       600\n",
      "\n",
      "    accuracy                         0.9061      3718\n",
      "   macro avg     0.7585    0.7519    0.7508      3718\n",
      "weighted avg     0.9033    0.9061    0.9035      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 329us/step - loss: 0.1914 - accuracy: 0.9278 - val_loss: 0.1585 - val_accuracy: 0.9431\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.1311 - accuracy: 0.9505 - val_loss: 0.1713 - val_accuracy: 0.9320\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.0938 - accuracy: 0.9648 - val_loss: 0.1788 - val_accuracy: 0.9369\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 316us/step - loss: 0.0536 - accuracy: 0.9806 - val_loss: 0.2242 - val_accuracy: 0.9341\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7317646750578026\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4534    0.3476    0.3935       210\n",
      "           1     0.9294    0.9553    0.9422      2908\n",
      "           2     0.8838    0.8367    0.8596       600\n",
      "\n",
      "    accuracy                         0.9018      3718\n",
      "   macro avg     0.7555    0.7132    0.7318      3718\n",
      "weighted avg     0.8952    0.9018    0.8979      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 5s 326us/step - loss: 0.1901 - accuracy: 0.9292 - val_loss: 0.1580 - val_accuracy: 0.9426\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 320us/step - loss: 0.1315 - accuracy: 0.9510 - val_loss: 0.1576 - val_accuracy: 0.9424\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.0903 - accuracy: 0.9665 - val_loss: 0.1789 - val_accuracy: 0.9343\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.0552 - accuracy: 0.9800 - val_loss: 0.2166 - val_accuracy: 0.9421\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7501017429746683\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5414    0.3429    0.4198       210\n",
      "           1     0.9400    0.9594    0.9496      2908\n",
      "           2     0.8687    0.8933    0.8809       600\n",
      "\n",
      "    accuracy                         0.9139      3718\n",
      "   macro avg     0.7834    0.7319    0.7501      3718\n",
      "weighted avg     0.9060    0.9139    0.9086      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 330us/step - loss: 0.1871 - accuracy: 0.9297 - val_loss: 0.1557 - val_accuracy: 0.9441\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 6s 337us/step - loss: 0.1277 - accuracy: 0.9512 - val_loss: 0.1800 - val_accuracy: 0.9352\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 6s 340us/step - loss: 0.0905 - accuracy: 0.9661 - val_loss: 0.1802 - val_accuracy: 0.9378\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 6s 336us/step - loss: 0.0493 - accuracy: 0.9827 - val_loss: 0.2384 - val_accuracy: 0.9280\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7174880441673972\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4795    0.3333    0.3933       210\n",
      "           1     0.9174    0.9622    0.9392      2908\n",
      "           2     0.8812    0.7667    0.8200       600\n",
      "\n",
      "    accuracy                         0.8951      3718\n",
      "   macro avg     0.7594    0.6874    0.7175      3718\n",
      "weighted avg     0.8868    0.8951    0.8892      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 330us/step - loss: 0.1900 - accuracy: 0.9276 - val_loss: 0.1589 - val_accuracy: 0.9426\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 321us/step - loss: 0.1318 - accuracy: 0.9514 - val_loss: 0.1606 - val_accuracy: 0.9414\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 322us/step - loss: 0.0941 - accuracy: 0.9653 - val_loss: 0.1770 - val_accuracy: 0.9386\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.0586 - accuracy: 0.9792 - val_loss: 0.2214 - val_accuracy: 0.9333\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7318750126667383\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4650    0.3476    0.3978       210\n",
      "           1     0.9291    0.9560    0.9424      2908\n",
      "           2     0.8787    0.8333    0.8554       600\n",
      "\n",
      "    accuracy                         0.9018      3718\n",
      "   macro avg     0.7576    0.7123    0.7319      3718\n",
      "weighted avg     0.8948    0.9018    0.8976      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 330us/step - loss: 0.1890 - accuracy: 0.9301 - val_loss: 0.1589 - val_accuracy: 0.9423\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 322us/step - loss: 0.1300 - accuracy: 0.9509 - val_loss: 0.1677 - val_accuracy: 0.9421\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 322us/step - loss: 0.0899 - accuracy: 0.9660 - val_loss: 0.1834 - val_accuracy: 0.9404\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 318us/step - loss: 0.0543 - accuracy: 0.9795 - val_loss: 0.2261 - val_accuracy: 0.9358\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7421084082834906\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4691    0.3619    0.4086       210\n",
      "           1     0.9458    0.9422    0.9440      2908\n",
      "           2     0.8346    0.9167    0.8737       600\n",
      "\n",
      "    accuracy                         0.9053      3718\n",
      "   macro avg     0.7498    0.7403    0.7421      3718\n",
      "weighted avg     0.9009    0.9053    0.9024      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 329us/step - loss: 0.1871 - accuracy: 0.9292 - val_loss: 0.1599 - val_accuracy: 0.9425\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 320us/step - loss: 0.1308 - accuracy: 0.9506 - val_loss: 0.1572 - val_accuracy: 0.9431\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 320us/step - loss: 0.0923 - accuracy: 0.9656 - val_loss: 0.2037 - val_accuracy: 0.9395\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 317us/step - loss: 0.0539 - accuracy: 0.9802 - val_loss: 0.2181 - val_accuracy: 0.9380\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7087920880736798\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4857    0.2429    0.3238       210\n",
      "           1     0.9249    0.9618    0.9430      2908\n",
      "           2     0.8676    0.8517    0.8595       600\n",
      "\n",
      "    accuracy                         0.9034      3718\n",
      "   macro avg     0.7594    0.6855    0.7088      3718\n",
      "weighted avg     0.8909    0.9034    0.8946      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 328us/step - loss: 0.1891 - accuracy: 0.9286 - val_loss: 0.1610 - val_accuracy: 0.9399\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 320us/step - loss: 0.1275 - accuracy: 0.9515 - val_loss: 0.1783 - val_accuracy: 0.9344\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 318us/step - loss: 0.0902 - accuracy: 0.9657 - val_loss: 0.1933 - val_accuracy: 0.9332\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 317us/step - loss: 0.0518 - accuracy: 0.9810 - val_loss: 0.2277 - val_accuracy: 0.9299\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7442002041043349\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4455    0.4286    0.4369       210\n",
      "           1     0.9328    0.9494    0.9410      2908\n",
      "           2     0.8885    0.8233    0.8547       600\n",
      "\n",
      "    accuracy                         0.8997      3718\n",
      "   macro avg     0.7556    0.7338    0.7442      3718\n",
      "weighted avg     0.8981    0.8997    0.8986      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 5s 326us/step - loss: 0.1896 - accuracy: 0.9294 - val_loss: 0.1555 - val_accuracy: 0.9434\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 317us/step - loss: 0.1292 - accuracy: 0.9504 - val_loss: 0.1622 - val_accuracy: 0.9404\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 317us/step - loss: 0.0911 - accuracy: 0.9659 - val_loss: 0.1938 - val_accuracy: 0.9415\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 316us/step - loss: 0.0524 - accuracy: 0.9807 - val_loss: 0.2160 - val_accuracy: 0.9351\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7260016243932844\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3978    0.3429    0.3683       210\n",
      "           1     0.9367    0.9412    0.9389      2908\n",
      "           2     0.8602    0.8817    0.8708       600\n",
      "\n",
      "    accuracy                         0.8978      3718\n",
      "   macro avg     0.7315    0.7219    0.7260      3718\n",
      "weighted avg     0.8939    0.8978    0.8957      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 331us/step - loss: 0.1942 - accuracy: 0.9267 - val_loss: 0.1645 - val_accuracy: 0.9427\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 322us/step - loss: 0.1327 - accuracy: 0.9505 - val_loss: 0.1628 - val_accuracy: 0.9428\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 321us/step - loss: 0.0978 - accuracy: 0.9640 - val_loss: 0.1870 - val_accuracy: 0.9302\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 318us/step - loss: 0.0616 - accuracy: 0.9775 - val_loss: 0.2219 - val_accuracy: 0.9307\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.73235926599015\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3922    0.4333    0.4118       210\n",
      "           1     0.9350    0.9405    0.9378      2908\n",
      "           2     0.8770    0.8200    0.8475       600\n",
      "\n",
      "    accuracy                         0.8924      3718\n",
      "   macro avg     0.7348    0.7313    0.7324      3718\n",
      "weighted avg     0.8950    0.8924    0.8935      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 331us/step - loss: 0.1885 - accuracy: 0.9301 - val_loss: 0.1676 - val_accuracy: 0.9426\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 319us/step - loss: 0.1346 - accuracy: 0.9493 - val_loss: 0.1637 - val_accuracy: 0.9388\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 321us/step - loss: 0.0979 - accuracy: 0.9639 - val_loss: 0.1790 - val_accuracy: 0.9411\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 322us/step - loss: 0.0618 - accuracy: 0.9772 - val_loss: 0.1937 - val_accuracy: 0.9362\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.731765305804391\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4581    0.3381    0.3890       210\n",
      "           1     0.9328    0.9546    0.9436      2908\n",
      "           2     0.8722    0.8533    0.8627       600\n",
      "\n",
      "    accuracy                         0.9034      3718\n",
      "   macro avg     0.7544    0.7153    0.7318      3718\n",
      "weighted avg     0.8962    0.9034    0.8992      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 330us/step - loss: 0.1881 - accuracy: 0.9295 - val_loss: 0.1624 - val_accuracy: 0.9424\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 318us/step - loss: 0.1280 - accuracy: 0.9527 - val_loss: 0.1594 - val_accuracy: 0.9437\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 321us/step - loss: 0.0913 - accuracy: 0.9660 - val_loss: 0.1826 - val_accuracy: 0.9339\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 322us/step - loss: 0.0524 - accuracy: 0.9812 - val_loss: 0.2486 - val_accuracy: 0.9309\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7465933782639119\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4163    0.4381    0.4269       210\n",
      "           1     0.9579    0.9237    0.9405      2908\n",
      "           2     0.8139    0.9400    0.8724       600\n",
      "\n",
      "    accuracy                         0.8989      3718\n",
      "   macro avg     0.7294    0.7673    0.7466      3718\n",
      "weighted avg     0.9041    0.8989    0.9005      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 332us/step - loss: 0.1878 - accuracy: 0.9302 - val_loss: 0.1617 - val_accuracy: 0.9405\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 318us/step - loss: 0.1285 - accuracy: 0.9518 - val_loss: 0.1609 - val_accuracy: 0.9430\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 320us/step - loss: 0.0920 - accuracy: 0.9655 - val_loss: 0.1949 - val_accuracy: 0.9423\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 320us/step - loss: 0.0564 - accuracy: 0.9792 - val_loss: 0.2183 - val_accuracy: 0.9356\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7176659492515792\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4483    0.3095    0.3662       210\n",
      "           1     0.9272    0.9501    0.9385      2908\n",
      "           2     0.8533    0.8433    0.8483       600\n",
      "\n",
      "    accuracy                         0.8967      3718\n",
      "   macro avg     0.7429    0.7010    0.7177      3718\n",
      "weighted avg     0.8882    0.8967    0.8916      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 331us/step - loss: 0.1892 - accuracy: 0.9292 - val_loss: 0.1737 - val_accuracy: 0.9355\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 320us/step - loss: 0.1300 - accuracy: 0.9506 - val_loss: 0.1594 - val_accuracy: 0.9444\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 321us/step - loss: 0.0919 - accuracy: 0.9660 - val_loss: 0.1956 - val_accuracy: 0.9272\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 318us/step - loss: 0.0585 - accuracy: 0.9781 - val_loss: 0.2919 - val_accuracy: 0.9380\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.620784175215111\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6364    0.0333    0.0633       210\n",
      "           1     0.9092    0.9780    0.9423      2908\n",
      "           2     0.8722    0.8417    0.8567       600\n",
      "\n",
      "    accuracy                         0.9026      3718\n",
      "   macro avg     0.8059    0.6177    0.6208      3718\n",
      "weighted avg     0.8878    0.9026    0.8789      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 333us/step - loss: 0.1913 - accuracy: 0.9268 - val_loss: 0.1611 - val_accuracy: 0.9415\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 323us/step - loss: 0.1313 - accuracy: 0.9508 - val_loss: 0.1685 - val_accuracy: 0.9437\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 321us/step - loss: 0.0965 - accuracy: 0.9639 - val_loss: 0.1777 - val_accuracy: 0.9397\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 322us/step - loss: 0.0593 - accuracy: 0.9779 - val_loss: 0.2132 - val_accuracy: 0.9384\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.7402439496093368\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4863    0.3381    0.3989       210\n",
      "           1     0.9408    0.9515    0.9461      2908\n",
      "           2     0.8542    0.8983    0.8757       600\n",
      "\n",
      "    accuracy                         0.9083      3718\n",
      "   macro avg     0.7604    0.7293    0.7402      3718\n",
      "weighted avg     0.9012    0.9083    0.9039      3718\n",
      "\n",
      "Train on 16852 samples, validate on 4213 samples\n",
      "Epoch 1/4\n",
      "16852/16852 [==============================] - 6s 333us/step - loss: 0.1882 - accuracy: 0.9303 - val_loss: 0.1569 - val_accuracy: 0.9442\n",
      "Epoch 2/4\n",
      "16852/16852 [==============================] - 5s 323us/step - loss: 0.1277 - accuracy: 0.9524 - val_loss: 0.1796 - val_accuracy: 0.9327\n",
      "Epoch 3/4\n",
      "16852/16852 [==============================] - 5s 323us/step - loss: 0.0910 - accuracy: 0.9656 - val_loss: 0.2003 - val_accuracy: 0.9254\n",
      "Epoch 4/4\n",
      "16852/16852 [==============================] - 5s 323us/step - loss: 0.0506 - accuracy: 0.9824 - val_loss: 0.2384 - val_accuracy: 0.9407\n",
      "--------- INDIVIDUAL CNN Model results ---------\n",
      "--------- F-1/precision/recall report  ---------\n",
      "---------         MACRO F1             ---------\n",
      "0.715427325857367\n",
      "---------         F1 Matrix            ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5426    0.2429    0.3355       210\n",
      "           1     0.9244    0.9673    0.9454      2908\n",
      "           2     0.8795    0.8517    0.8654       600\n",
      "\n",
      "    accuracy                         0.9077      3718\n",
      "   macro avg     0.7822    0.6873    0.7154      3718\n",
      "weighted avg     0.8956    0.9077    0.8980      3718\n",
      "\n",
      "3718 3718 3718\n",
      "--------- FINAL ENSEMBLE Model results ---------\n",
      "---------  F-1/precision/recall report ---------\n",
      "---------            MACRO F1:         ---------\n",
      "0.7445191493690873\n",
      "---------            F1 Matrix         ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5227    0.3286    0.4035       210\n",
      "           1     0.9389    0.9570    0.9479      2908\n",
      "           2     0.8666    0.8983    0.8822       600\n",
      "\n",
      "    accuracy                         0.9120      3718\n",
      "   macro avg     0.7761    0.7280    0.7445      3718\n",
      "weighted avg     0.9037    0.9120    0.9065      3718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble10 = Ensemble_CNN_model(random_seed=101, num_ensemble_models=20)\n",
    "\n",
    "class_weight = {0: 4.,\n",
    "                1: 1.,\n",
    "                2: 1.}\n",
    "\n",
    "ensemble10.fit_and_eval(X_train_split, y_train_split, X_test_split, y_test_split,\n",
    "                        epochs=4, batch_size=32, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZdMY1enX_9y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "NN Ensemble wordToVec.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
